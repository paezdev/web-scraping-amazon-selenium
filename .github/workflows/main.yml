name: Pipeline de Scraping

on:
  push:
    branches:
      - main  # Ejecuta el pipeline al hacer push en la rama principal

jobs:
  run-scraping:
    runs-on: ubuntu-latest

    steps:
      # Paso 1: Clonar el código del repositorio
      - name: Checkout code
        uses: actions/checkout@v2

      # Paso 2: Configurar Python
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      # Paso 3: Instalar dependencias
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install webdriver-manager

      # Paso 4: Instalar Brave Browser (si es necesario)
      - name: Install Brave Browser
        run: |
          sudo apt-get update
          sudo apt-get install -y apt-transport-https curl
          sudo curl -fsSLo /usr/share/keyrings/brave-browser-archive-keyring.gpg https://brave-browser-apt-release.s3.brave.com/brave-browser-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/brave-browser-archive-keyring.gpg] https://brave-browser-apt-release.s3.brave.com/ stable main" | sudo tee /etc/apt/sources.list.d/brave-browser-release.list
          sudo apt-get update
          sudo apt-get install -y brave-browser

      # Paso 5: Verificar que Brave está instalado
      - name: Check Brave Browser installation
        run: |
          which brave-browser
          brave-browser --version

      # Paso 6: Ejecutar el script de scraping
      - name: Run scraping script
        run: python PáezRamírez_JeanCarlos_Analizando_EA1.py

      # Paso 7: Ejecutar pruebas automatizadas con pytest
      - name: Run tests
        run: |
          pytest

      # Paso 8: Subir los archivos generados como artefactos
      - name: Upload Data as Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: scraped-data
          path: |
            output.csv
            error_screenshot.png
            success_screenshot.png
            product_details.txt  # Asegúrate de incluir este archivo

      # Paso 9: Verificar estado de git (opcional)
      - name: Verificar estado de git
        run: |
          git status
          git remote -v

      # Paso 10: Hacer commit de los archivos generados al repositorio
      - name: Push Results to Repository
        if: success()
        env:
          SCRAPING: ${{ secrets.SCRAPING }}
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git remote set-url origin https://x-access-token:${SCRAPING}@github.com/${{ github.repository }}

          # Verificar si hay cambios
          if [[ -f output.csv && -f success_screenshot.png ]]; then
            git add output.csv
            git add success_screenshot.png
            git add error_screenshot.png || true
            git add product_details.txt || true

            # Verificar si hay cambios para hacer commit
            if git diff --staged --quiet; then
              echo "No hay cambios para hacer commit"
            else
              git commit -m "Actualización automática de datos extraídos [skip ci]"
              git push origin main
            fi
          else
            echo "No se encontraron los archivos necesarios para hacer commit"
          fi
